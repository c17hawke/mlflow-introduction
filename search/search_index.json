{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Welcome to Documentation of MLFlow-introduction course Official MLFlow Documenation MLflow.org Contents Topic SubTopic Section: 1 MLflow Introduction Introduction to MLflow Installation and first trial of MLflow Section: 2 MLflow Tracking Simple ML model Logging our simple ML model using Exploring UI of MLflow Packaging a project MLflow way MLflow tracking server","title":"Home"},{"location":"#welcome-to-documentation-of-mlflow-introduction-course","text":"","title":"Welcome to Documentation of MLFlow-introduction course"},{"location":"#official-mlflow-documenation","text":"MLflow.org","title":"Official MLFlow Documenation"},{"location":"#contents","text":"Topic SubTopic Section: 1 MLflow Introduction Introduction to MLflow Installation and first trial of MLflow Section: 2 MLflow Tracking Simple ML model Logging our simple ML model using Exploring UI of MLflow Packaging a project MLflow way MLflow tracking server","title":"Contents"},{"location":"Section_001_MLflow_Introduction/","text":"Section: 1 MLflow Introduction Introduction to MLflow What is MLflow ? MLflow is an open source platform for managing the machine learning lifecycle from start to finish. MLflow is organized into four components: Tracking, Projects, Models, and Model Registry.Each of these components can be used independently. That means we can still track the model\u2019s performance without exporting models in MLflow\u2019s model format. MLflow is designed to put as few constraints as possible and make codebase written in its format reproducible and reusable by multiple data scientists. MLflow Components Installation and first trial of MLflow First create the conda environment by the following command - conda create --prefix ./env python = 3 .7 -y activate environment conda actiavate ./env To use MLflow as a Python library, install it using pip . You can install MLflow by running: pip install mlflow Create the files as mentioned in the video lecture. Source code","title":"Section 01 Intorduction to MLflow"},{"location":"Section_001_MLflow_Introduction/#section-1-mlflow-introduction","text":"","title":"Section: 1 MLflow Introduction"},{"location":"Section_001_MLflow_Introduction/#introduction-to-mlflow","text":"","title":"Introduction to MLflow"},{"location":"Section_001_MLflow_Introduction/#what-is-mlflow","text":"MLflow is an open source platform for managing the machine learning lifecycle from start to finish. MLflow is organized into four components: Tracking, Projects, Models, and Model Registry.Each of these components can be used independently. That means we can still track the model\u2019s performance without exporting models in MLflow\u2019s model format. MLflow is designed to put as few constraints as possible and make codebase written in its format reproducible and reusable by multiple data scientists.","title":"What is MLflow?"},{"location":"Section_001_MLflow_Introduction/#mlflow-components","text":"","title":"MLflow Components"},{"location":"Section_001_MLflow_Introduction/#installation-and-first-trial-of-mlflow","text":"First create the conda environment by the following command - conda create --prefix ./env python = 3 .7 -y activate environment conda actiavate ./env To use MLflow as a Python library, install it using pip . You can install MLflow by running: pip install mlflow Create the files as mentioned in the video lecture. Source code","title":"Installation and first trial of MLflow"},{"location":"Section_002_MLflow_Tracking/","text":"Section 2: MLflow Tracking Simple ML model - We have implemented a simple ML model to showcase the experiment tracking concept used in MLflow- Source code simple_ML_model.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 import os import argparse import pandas as pd import numpy as np from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score from sklearn.model_selection import train_test_split from sklearn.linear_model import ElasticNet from urllib.parse import urlparse import mlflow import mlflow.sklearn def get_data (): URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\" try : df = pd . read_csv ( URL , sep = \";\" ) return df except Exception as e : raise e def evaluate ( actual , pred ): rmse = np . sqrt ( mean_squared_error ( actual , pred )) mae = mean_absolute_error ( actual , pred ) r2 = r2_score ( actual , pred ) return rmse , mae , r2 def main ( alpha , l1_ratio ): df = get_data () train , test = train_test_split ( df ) train_x = train . drop ([ \"quality\" ], axis = 1 ) test_x = test . drop ([ \"quality\" ], axis = 1 ) train_y = train [[ \"quality\" ]] test_y = test [[ \"quality\" ]] # mlflow with mlflow . start_run (): lr = ElasticNet ( alpha = alpha , l1_ratio = l1_ratio , random_state = 42 ) lr . fit ( train_x , train_y ) pred = lr . predict ( test_x ) rmse , mae , r2 = evaluate ( test_y , pred ) print ( f \"Elastic net params: alpha: { alpha } , l1_ratio: { l1_ratio } \" ) print ( f \"Elastic net metric: rmse: { rmse } , mae: { mae } , r2: { r2 } \" ) mlflow . log_param ( \"alpha\" , alpha ) mlflow . log_param ( \"l1_ratio\" , l1_ratio ) mlflow . log_metric ( \"rmse\" , rmse ) mlflow . log_metric ( \"mae\" , mae ) mlflow . log_metric ( \"r2\" , r2 ) if __name__ == \"__main__\" : args = argparse . ArgumentParser () args . add_argument ( \"--alpha\" , \"-a\" , type = float , default = 0.5 ) args . add_argument ( \"--l1_ratio\" , \"-l1\" , type = float , default = 0.5 ) parsed_args = args . parse_args () try : main ( alpha = parsed_args . alpha , l1_ratio = parsed_args . l1_ratio ) except Exception as e : raise e Source repository - Click here Concept of Runs MLflow Tracking is based on runs. Runs are executions of some piece of data science code. A Run can record the following : Code Version Start & End Time Source Parameters Metrics Artifacts Logging our simple ML model using In this lecture it has been shown that how we can log our model for every execution or experiment- Source code simple_ML_model_2.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 import os import argparse import pandas as pd import numpy as np from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score from sklearn.model_selection import train_test_split from sklearn.linear_model import ElasticNet from urllib.parse import urlparse import mlflow import mlflow.sklearn def get_data (): URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\" try : df = pd . read_csv ( URL , sep = \";\" ) return df except Exception as e : raise e def evaluate ( actual , pred ): rmse = np . sqrt ( mean_squared_error ( actual , pred )) mae = mean_absolute_error ( actual , pred ) r2 = r2_score ( actual , pred ) return rmse , mae , r2 def main ( alpha , l1_ratio ): df = get_data () train , test = train_test_split ( df ) train_x = train . drop ([ \"quality\" ], axis = 1 ) test_x = test . drop ([ \"quality\" ], axis = 1 ) train_y = train [[ \"quality\" ]] test_y = test [[ \"quality\" ]] # mlflow with mlflow . start_run (): lr = ElasticNet ( alpha = alpha , l1_ratio = l1_ratio , random_state = 42 ) lr . fit ( train_x , train_y ) pred = lr . predict ( test_x ) rmse , mae , r2 = evaluate ( test_y , pred ) print ( f \"Elastic net params: alpha: { alpha } , l1_ratio: { l1_ratio } \" ) print ( f \"Elastic net metric: rmse: { rmse } , mae: { mae } , r2: { r2 } \" ) mlflow . log_param ( \"alpha\" , alpha ) mlflow . log_param ( \"l1_ratio\" , l1_ratio ) mlflow . log_metric ( \"rmse\" , rmse ) mlflow . log_metric ( \"mae\" , mae ) mlflow . log_metric ( \"r2\" , r2 ) # mlflow model logging mlflow . sklearn . log_model ( lr , \"model\" ) if __name__ == \"__main__\" : args = argparse . ArgumentParser () args . add_argument ( \"--alpha\" , \"-a\" , type = float , default = 0.5 ) args . add_argument ( \"--l1_ratio\" , \"-l1\" , type = float , default = 0.5 ) parsed_args = args . parse_args () try : main ( alpha = parsed_args . alpha , l1_ratio = parsed_args . l1_ratio ) except Exception as e : raise e Exploring UI of MLflow runs.py import numpy as np import os alpha_s = np . linspace ( 0.1 , 1.0 , 5 ) l1_ratios = np . linspace ( 0.1 , 1.0 , 5 ) for alpha in alpha_s : for l1 in l1_ratios : os . system ( f \"python simple_ML_model_2.py -a { alpha } -l1 { l1 } \" ) Info Refer video lecture for this in oneNeuron platform for UI exploration Packaging a project MLflow way Create a conda.yaml file as shown below: conda.yaml name : mlflow_tutorial channels : - defaults dependencies : - python=3.7.11=h6244533_0 - pip=21.2.4=py37haa95532_0 - pip : - mlflow==1.23.1 - numpy==1.21.5 - pandas==1.3.5 - scikit-learn==1.0.2 or run the following command to create conda.yaml file conda env export > conda.yaml Note make sure you are in the same environment while running the command whose conda.yaml file you wish to create after above step create the an MLproject file in the root of the project as shown below - MLproject name : mlflow_tutorial conda_env : conda.yaml entry_points : main : parameters : alpha : { type : float , default : 0.5 } l1_ratio : { type : float , default : 0.5 } command : \"python simple_ML_model_2.py -a {alpha} -l1 {l1_ratio}\" Now run the following command to execte the project without using a fresh conda environment by using the existing environment- mlflow run . --no-conda with a fresh conda environment - mlflow run . if you wish to pass command line argument then use the below command- mlflow run . -P alpha = 0 .7 -P l1_ratio = 0 .4 source code for the above demo - source code MLflow tracking server make the changes in the code base to be ready for tracking server - code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 import os import argparse import pandas as pd import numpy as np from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score from sklearn.model_selection import train_test_split from sklearn.linear_model import ElasticNet from urllib.parse import urlparse import mlflow import mlflow.sklearn def get_data (): URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\" try : df = pd . read_csv ( URL , sep = \";\" ) return df except Exception as e : raise e def evaluate ( actual , pred ): rmse = np . sqrt ( mean_squared_error ( actual , pred )) mae = mean_absolute_error ( actual , pred ) r2 = r2_score ( actual , pred ) return rmse , mae , r2 def main ( alpha , l1_ratio , tracking_uri , port ): df = get_data () train , test = train_test_split ( df ) train_x = train . drop ([ \"quality\" ], axis = 1 ) test_x = test . drop ([ \"quality\" ], axis = 1 ) train_y = train [[ \"quality\" ]] test_y = test [[ \"quality\" ]] # mlflow tracking URI URI = f \"http:// { tracking_uri } : { port } \" mlflow . set_tracking_uri ( URI ) # mlflow with mlflow . start_run (): lr = ElasticNet ( alpha = alpha , l1_ratio = l1_ratio , random_state = 42 ) lr . fit ( train_x , train_y ) pred = lr . predict ( test_x ) rmse , mae , r2 = evaluate ( test_y , pred ) print ( f \"Elastic net params: alpha: { alpha } , l1_ratio: { l1_ratio } \" ) print ( f \"Elastic net metric: rmse: { rmse } , mae: { mae } , r2: { r2 } \" ) mlflow . log_param ( \"alpha\" , alpha ) mlflow . log_param ( \"l1_ratio\" , l1_ratio ) mlflow . log_metric ( \"rmse\" , rmse ) mlflow . log_metric ( \"mae\" , mae ) mlflow . log_metric ( \"r2\" , r2 ) # register model in the sql server mlflow . sklearn . log_model ( lr , \"model\" , registered_model_name = \"ENmodel\" ) if __name__ == \"__main__\" : args = argparse . ArgumentParser () args . add_argument ( \"--alpha\" , \"-a\" , type = float , default = 0.5 ) args . add_argument ( \"--l1_ratio\" , \"-l1\" , type = float , default = 0.5 ) args . add_argument ( \"--tracking_uri\" , \"-t\" , type = str , default = \"localhost\" ) args . add_argument ( \"--port\" , \"-p\" , type = int , default = 5000 ) parsed_args = args . parse_args () try : main ( alpha = parsed_args . alpha , l1_ratio = parsed_args . l1_ratio , tracking_uri = parsed_args . tracking_uri , port = parsed_args . port ) except Exception as e : raise e run mlflow sqlite server to store parameters and metrics in an sqlite local database and create artifact directory to store files mlflow server \\ --backend-store-uri sqlite:///mlflow.db \\ --default-artifact-root ./artifacts \\ --host 0 .0.0.0 -p 1234 Info To create command using conda env file [an alternative to pip install -r requirements.txt] conda env create --prefix ./env -f conda.yaml","title":"Section 02 MLflow Tracking"},{"location":"Section_002_MLflow_Tracking/#section-2-mlflow-tracking","text":"","title":"Section 2: MLflow Tracking"},{"location":"Section_002_MLflow_Tracking/#simple-ml-model-","text":"We have implemented a simple ML model to showcase the experiment tracking concept used in MLflow-","title":"Simple ML model -"},{"location":"Section_002_MLflow_Tracking/#source-code","text":"simple_ML_model.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 import os import argparse import pandas as pd import numpy as np from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score from sklearn.model_selection import train_test_split from sklearn.linear_model import ElasticNet from urllib.parse import urlparse import mlflow import mlflow.sklearn def get_data (): URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\" try : df = pd . read_csv ( URL , sep = \";\" ) return df except Exception as e : raise e def evaluate ( actual , pred ): rmse = np . sqrt ( mean_squared_error ( actual , pred )) mae = mean_absolute_error ( actual , pred ) r2 = r2_score ( actual , pred ) return rmse , mae , r2 def main ( alpha , l1_ratio ): df = get_data () train , test = train_test_split ( df ) train_x = train . drop ([ \"quality\" ], axis = 1 ) test_x = test . drop ([ \"quality\" ], axis = 1 ) train_y = train [[ \"quality\" ]] test_y = test [[ \"quality\" ]] # mlflow with mlflow . start_run (): lr = ElasticNet ( alpha = alpha , l1_ratio = l1_ratio , random_state = 42 ) lr . fit ( train_x , train_y ) pred = lr . predict ( test_x ) rmse , mae , r2 = evaluate ( test_y , pred ) print ( f \"Elastic net params: alpha: { alpha } , l1_ratio: { l1_ratio } \" ) print ( f \"Elastic net metric: rmse: { rmse } , mae: { mae } , r2: { r2 } \" ) mlflow . log_param ( \"alpha\" , alpha ) mlflow . log_param ( \"l1_ratio\" , l1_ratio ) mlflow . log_metric ( \"rmse\" , rmse ) mlflow . log_metric ( \"mae\" , mae ) mlflow . log_metric ( \"r2\" , r2 ) if __name__ == \"__main__\" : args = argparse . ArgumentParser () args . add_argument ( \"--alpha\" , \"-a\" , type = float , default = 0.5 ) args . add_argument ( \"--l1_ratio\" , \"-l1\" , type = float , default = 0.5 ) parsed_args = args . parse_args () try : main ( alpha = parsed_args . alpha , l1_ratio = parsed_args . l1_ratio ) except Exception as e : raise e Source repository - Click here","title":"Source code"},{"location":"Section_002_MLflow_Tracking/#concept-of-runs","text":"MLflow Tracking is based on runs. Runs are executions of some piece of data science code. A Run can record the following : Code Version Start & End Time Source Parameters Metrics Artifacts","title":"Concept of Runs"},{"location":"Section_002_MLflow_Tracking/#logging-our-simple-ml-model-using","text":"In this lecture it has been shown that how we can log our model for every execution or experiment-","title":"Logging our simple ML model using"},{"location":"Section_002_MLflow_Tracking/#source-code_1","text":"simple_ML_model_2.py 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 import os import argparse import pandas as pd import numpy as np from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score from sklearn.model_selection import train_test_split from sklearn.linear_model import ElasticNet from urllib.parse import urlparse import mlflow import mlflow.sklearn def get_data (): URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\" try : df = pd . read_csv ( URL , sep = \";\" ) return df except Exception as e : raise e def evaluate ( actual , pred ): rmse = np . sqrt ( mean_squared_error ( actual , pred )) mae = mean_absolute_error ( actual , pred ) r2 = r2_score ( actual , pred ) return rmse , mae , r2 def main ( alpha , l1_ratio ): df = get_data () train , test = train_test_split ( df ) train_x = train . drop ([ \"quality\" ], axis = 1 ) test_x = test . drop ([ \"quality\" ], axis = 1 ) train_y = train [[ \"quality\" ]] test_y = test [[ \"quality\" ]] # mlflow with mlflow . start_run (): lr = ElasticNet ( alpha = alpha , l1_ratio = l1_ratio , random_state = 42 ) lr . fit ( train_x , train_y ) pred = lr . predict ( test_x ) rmse , mae , r2 = evaluate ( test_y , pred ) print ( f \"Elastic net params: alpha: { alpha } , l1_ratio: { l1_ratio } \" ) print ( f \"Elastic net metric: rmse: { rmse } , mae: { mae } , r2: { r2 } \" ) mlflow . log_param ( \"alpha\" , alpha ) mlflow . log_param ( \"l1_ratio\" , l1_ratio ) mlflow . log_metric ( \"rmse\" , rmse ) mlflow . log_metric ( \"mae\" , mae ) mlflow . log_metric ( \"r2\" , r2 ) # mlflow model logging mlflow . sklearn . log_model ( lr , \"model\" ) if __name__ == \"__main__\" : args = argparse . ArgumentParser () args . add_argument ( \"--alpha\" , \"-a\" , type = float , default = 0.5 ) args . add_argument ( \"--l1_ratio\" , \"-l1\" , type = float , default = 0.5 ) parsed_args = args . parse_args () try : main ( alpha = parsed_args . alpha , l1_ratio = parsed_args . l1_ratio ) except Exception as e : raise e","title":"Source code"},{"location":"Section_002_MLflow_Tracking/#exploring-ui-of-mlflow","text":"runs.py import numpy as np import os alpha_s = np . linspace ( 0.1 , 1.0 , 5 ) l1_ratios = np . linspace ( 0.1 , 1.0 , 5 ) for alpha in alpha_s : for l1 in l1_ratios : os . system ( f \"python simple_ML_model_2.py -a { alpha } -l1 { l1 } \" ) Info Refer video lecture for this in oneNeuron platform for UI exploration","title":"Exploring UI of MLflow"},{"location":"Section_002_MLflow_Tracking/#packaging-a-project-mlflow-way","text":"Create a conda.yaml file as shown below: conda.yaml name : mlflow_tutorial channels : - defaults dependencies : - python=3.7.11=h6244533_0 - pip=21.2.4=py37haa95532_0 - pip : - mlflow==1.23.1 - numpy==1.21.5 - pandas==1.3.5 - scikit-learn==1.0.2 or run the following command to create conda.yaml file conda env export > conda.yaml Note make sure you are in the same environment while running the command whose conda.yaml file you wish to create after above step create the an MLproject file in the root of the project as shown below - MLproject name : mlflow_tutorial conda_env : conda.yaml entry_points : main : parameters : alpha : { type : float , default : 0.5 } l1_ratio : { type : float , default : 0.5 } command : \"python simple_ML_model_2.py -a {alpha} -l1 {l1_ratio}\" Now run the following command to execte the project without using a fresh conda environment by using the existing environment- mlflow run . --no-conda with a fresh conda environment - mlflow run . if you wish to pass command line argument then use the below command- mlflow run . -P alpha = 0 .7 -P l1_ratio = 0 .4 source code for the above demo - source code","title":"Packaging a project MLflow way"},{"location":"Section_002_MLflow_Tracking/#mlflow-tracking-server","text":"make the changes in the code base to be ready for tracking server - code 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 import os import argparse import pandas as pd import numpy as np from sklearn.metrics import mean_squared_error , mean_absolute_error , r2_score from sklearn.model_selection import train_test_split from sklearn.linear_model import ElasticNet from urllib.parse import urlparse import mlflow import mlflow.sklearn def get_data (): URL = \"http://archive.ics.uci.edu/ml/machine-learning-databases/wine-quality/winequality-red.csv\" try : df = pd . read_csv ( URL , sep = \";\" ) return df except Exception as e : raise e def evaluate ( actual , pred ): rmse = np . sqrt ( mean_squared_error ( actual , pred )) mae = mean_absolute_error ( actual , pred ) r2 = r2_score ( actual , pred ) return rmse , mae , r2 def main ( alpha , l1_ratio , tracking_uri , port ): df = get_data () train , test = train_test_split ( df ) train_x = train . drop ([ \"quality\" ], axis = 1 ) test_x = test . drop ([ \"quality\" ], axis = 1 ) train_y = train [[ \"quality\" ]] test_y = test [[ \"quality\" ]] # mlflow tracking URI URI = f \"http:// { tracking_uri } : { port } \" mlflow . set_tracking_uri ( URI ) # mlflow with mlflow . start_run (): lr = ElasticNet ( alpha = alpha , l1_ratio = l1_ratio , random_state = 42 ) lr . fit ( train_x , train_y ) pred = lr . predict ( test_x ) rmse , mae , r2 = evaluate ( test_y , pred ) print ( f \"Elastic net params: alpha: { alpha } , l1_ratio: { l1_ratio } \" ) print ( f \"Elastic net metric: rmse: { rmse } , mae: { mae } , r2: { r2 } \" ) mlflow . log_param ( \"alpha\" , alpha ) mlflow . log_param ( \"l1_ratio\" , l1_ratio ) mlflow . log_metric ( \"rmse\" , rmse ) mlflow . log_metric ( \"mae\" , mae ) mlflow . log_metric ( \"r2\" , r2 ) # register model in the sql server mlflow . sklearn . log_model ( lr , \"model\" , registered_model_name = \"ENmodel\" ) if __name__ == \"__main__\" : args = argparse . ArgumentParser () args . add_argument ( \"--alpha\" , \"-a\" , type = float , default = 0.5 ) args . add_argument ( \"--l1_ratio\" , \"-l1\" , type = float , default = 0.5 ) args . add_argument ( \"--tracking_uri\" , \"-t\" , type = str , default = \"localhost\" ) args . add_argument ( \"--port\" , \"-p\" , type = int , default = 5000 ) parsed_args = args . parse_args () try : main ( alpha = parsed_args . alpha , l1_ratio = parsed_args . l1_ratio , tracking_uri = parsed_args . tracking_uri , port = parsed_args . port ) except Exception as e : raise e run mlflow sqlite server to store parameters and metrics in an sqlite local database and create artifact directory to store files mlflow server \\ --backend-store-uri sqlite:///mlflow.db \\ --default-artifact-root ./artifacts \\ --host 0 .0.0.0 -p 1234 Info To create command using conda env file [an alternative to pip install -r requirements.txt] conda env create --prefix ./env -f conda.yaml","title":"MLflow tracking server"}]}